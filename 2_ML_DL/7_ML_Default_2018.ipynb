{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbbc366f-8000-470d-bc48-42b978854e54",
   "metadata": {},
   "source": [
    "# Machine Learning Models on the IDS 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba23740-21e7-4172-99fb-3b3cc3ac4914",
   "metadata": {},
   "source": [
    "In this notebook, deicision tree and random forest based machine learning algorithms are applied\n",
    "to the ids2018 dataset. Several methods for resolving the class imbalance are tested. Decision\n",
    "tree algorithms were chosen for their effectiveness and the training time which were better than\n",
    "other machine learning models. RT and RF based algorithms performed better in the preliminary\n",
    "experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90afc897-6301-4784-9991-554949bfc9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1/10 files.\n",
      "Processed 2/10 files.\n",
      "Processed 3/10 files.\n",
      "Processed 4/10 files.\n",
      "Processed 5/10 files.\n",
      "Processed 6/10 files.\n",
      "Processed 7/10 files.\n",
      "Processed 8/10 files.\n",
      "Processed 9/10 files.\n",
      "Processed 10/10 files.\n",
      "Creating is_attack column...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1623303 entries, 0 to 1623302\n",
      "Data columns (total 81 columns):\n",
      " #   Column             Non-Null Count    Dtype   \n",
      "---  ------             --------------    -----   \n",
      " 0   dst_port           1623295 non-null  float64 \n",
      " 1   protocol           1623295 non-null  float64 \n",
      " 2   timestamp          0 non-null        float64 \n",
      " 3   flow_duration      1623295 non-null  float64 \n",
      " 4   tot_fwd_pkts       1623295 non-null  float64 \n",
      " 5   tot_bwd_pkts       1623295 non-null  float64 \n",
      " 6   totlen_fwd_pkts    1623295 non-null  float64 \n",
      " 7   totlen_bwd_pkts    1623295 non-null  float64 \n",
      " 8   fwd_pkt_len_max    1623295 non-null  float64 \n",
      " 9   fwd_pkt_len_min    1623295 non-null  float64 \n",
      " 10  fwd_pkt_len_mean   1623295 non-null  float64 \n",
      " 11  fwd_pkt_len_std    1623295 non-null  float64 \n",
      " 12  bwd_pkt_len_max    1623295 non-null  float64 \n",
      " 13  bwd_pkt_len_min    1623295 non-null  float64 \n",
      " 14  bwd_pkt_len_mean   1623295 non-null  float64 \n",
      " 15  bwd_pkt_len_std    1623295 non-null  float64 \n",
      " 16  flow_byts_s        1617377 non-null  float64 \n",
      " 17  flow_pkts_s        1623295 non-null  float64 \n",
      " 18  flow_iat_mean      1623295 non-null  float64 \n",
      " 19  flow_iat_std       1623295 non-null  float64 \n",
      " 20  flow_iat_max       1623295 non-null  float64 \n",
      " 21  flow_iat_min       1623295 non-null  float64 \n",
      " 22  fwd_iat_tot        1623295 non-null  float64 \n",
      " 23  fwd_iat_mean       1623295 non-null  float64 \n",
      " 24  fwd_iat_std        1623295 non-null  float64 \n",
      " 25  fwd_iat_max        1623295 non-null  float64 \n",
      " 26  fwd_iat_min        1623295 non-null  float64 \n",
      " 27  bwd_iat_tot        1623295 non-null  float64 \n",
      " 28  bwd_iat_mean       1623295 non-null  float64 \n",
      " 29  bwd_iat_std        1623295 non-null  float64 \n",
      " 30  bwd_iat_max        1623295 non-null  float64 \n",
      " 31  bwd_iat_min        1623295 non-null  float64 \n",
      " 32  fwd_psh_flags      1623295 non-null  float64 \n",
      " 33  bwd_psh_flags      1623295 non-null  float64 \n",
      " 34  fwd_urg_flags      1623295 non-null  float64 \n",
      " 35  bwd_urg_flags      1623295 non-null  float64 \n",
      " 36  fwd_header_len     1623295 non-null  float64 \n",
      " 37  bwd_header_len     1623295 non-null  float64 \n",
      " 38  fwd_pkts_s         1623295 non-null  float64 \n",
      " 39  bwd_pkts_s         1623295 non-null  float64 \n",
      " 40  pkt_len_min        1623295 non-null  float64 \n",
      " 41  pkt_len_max        1623295 non-null  float64 \n",
      " 42  pkt_len_mean       1623295 non-null  float64 \n",
      " 43  pkt_len_std        1623295 non-null  float64 \n",
      " 44  pkt_len_var        1623295 non-null  float64 \n",
      " 45  fin_flag_cnt       1623295 non-null  float64 \n",
      " 46  syn_flag_cnt       1623295 non-null  float64 \n",
      " 47  rst_flag_cnt       1623295 non-null  float64 \n",
      " 48  psh_flag_cnt       1623295 non-null  float64 \n",
      " 49  ack_flag_cnt       1623295 non-null  float64 \n",
      " 50  urg_flag_cnt       1623295 non-null  float64 \n",
      " 51  cwe_flag_count     1623295 non-null  float64 \n",
      " 52  ece_flag_cnt       1623295 non-null  float64 \n",
      " 53  down_up_ratio      1623295 non-null  float64 \n",
      " 54  pkt_size_avg       1623295 non-null  float64 \n",
      " 55  fwd_seg_size_avg   1623295 non-null  float64 \n",
      " 56  bwd_seg_size_avg   1623295 non-null  float64 \n",
      " 57  fwd_byts_b_avg     1623295 non-null  float64 \n",
      " 58  fwd_pkts_b_avg     1623295 non-null  float64 \n",
      " 59  fwd_blk_rate_avg   1623295 non-null  float64 \n",
      " 60  bwd_byts_b_avg     1623295 non-null  float64 \n",
      " 61  bwd_pkts_b_avg     1623295 non-null  float64 \n",
      " 62  bwd_blk_rate_avg   1623295 non-null  float64 \n",
      " 63  subflow_fwd_pkts   1623295 non-null  float64 \n",
      " 64  subflow_fwd_byts   1623295 non-null  float64 \n",
      " 65  subflow_bwd_pkts   1623295 non-null  float64 \n",
      " 66  subflow_bwd_byts   1623295 non-null  float64 \n",
      " 67  init_fwd_win_byts  1623295 non-null  float64 \n",
      " 68  init_bwd_win_byts  1623295 non-null  float64 \n",
      " 69  fwd_act_data_pkts  1623295 non-null  float64 \n",
      " 70  fwd_seg_size_min   1623295 non-null  float64 \n",
      " 71  active_mean        1623295 non-null  float64 \n",
      " 72  active_std         1623295 non-null  float64 \n",
      " 73  active_max         1623295 non-null  float64 \n",
      " 74  active_min         1623295 non-null  float64 \n",
      " 75  idle_mean          1623295 non-null  float64 \n",
      " 76  idle_std           1623295 non-null  float64 \n",
      " 77  idle_max           1623295 non-null  float64 \n",
      " 78  idle_min           1623295 non-null  float64 \n",
      " 79  label              1623303 non-null  category\n",
      " 80  is_attack          1623303 non-null  int64   \n",
      "dtypes: category(1), float64(79), int64(1)\n",
      "memory usage: 992.3 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import os\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, average_precision_score, make_scorer, precision_score, accuracy_score, confusion_matrix, recall_score, f1_score, roc_auc_score\n",
    "from notebook_utils import load_sample_dataset_2018\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "file_path = r\"..\\CIC-IDS-2018\\Processed Traffic Data for ML Algorithms\"\n",
    "\n",
    "attack_labels = {\n",
    "    0: 'Benign',\n",
    "    1: 'Bot',\n",
    "    2: 'Brute Force -Web',\n",
    "    3: 'Brute Force -XSS',\n",
    "    4: 'DDOS attack-HOIC',\n",
    "    5: 'DDOS attack-LOIC-UDP',\n",
    "    6: 'DDoS attacks-LOIC-HTTP',\n",
    "    7: 'DoS attacks-GoldenEye',\n",
    "    8: 'DoS attacks-Hulk',\n",
    "    9: 'DoS attacks-SlowHTTPTest',\n",
    "    10: 'DoS attacks-Slowloris',\n",
    "    11: 'FTP-BruteForce',\n",
    "    12: 'Infilteration',\n",
    "    13: 'SQL Injection',\n",
    "    14: 'SSH-Bruteforce'\n",
    "}\n",
    "\n",
    "df = load_sample_dataset_2018(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6861bdc7-9e7e-4bb9-9820-35013126609f",
   "metadata": {},
   "source": [
    "## Preparing the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3d787e-8b1f-4ad6-8aaa-87583203f63a",
   "metadata": {},
   "source": [
    "### Check for invalid values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2300cbac-769a-43b7-a2ff-1cc560f678b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with NaN values: ['dst_port', 'protocol', 'timestamp', 'flow_duration', 'tot_fwd_pkts', 'tot_bwd_pkts', 'totlen_fwd_pkts', 'totlen_bwd_pkts', 'fwd_pkt_len_max', 'fwd_pkt_len_min', 'fwd_pkt_len_mean', 'fwd_pkt_len_std', 'bwd_pkt_len_max', 'bwd_pkt_len_min', 'bwd_pkt_len_mean', 'bwd_pkt_len_std', 'flow_byts_s', 'flow_pkts_s', 'flow_iat_mean', 'flow_iat_std', 'flow_iat_max', 'flow_iat_min', 'fwd_iat_tot', 'fwd_iat_mean', 'fwd_iat_std', 'fwd_iat_max', 'fwd_iat_min', 'bwd_iat_tot', 'bwd_iat_mean', 'bwd_iat_std', 'bwd_iat_max', 'bwd_iat_min', 'fwd_psh_flags', 'bwd_psh_flags', 'fwd_urg_flags', 'bwd_urg_flags', 'fwd_header_len', 'bwd_header_len', 'fwd_pkts_s', 'bwd_pkts_s', 'pkt_len_min', 'pkt_len_max', 'pkt_len_mean', 'pkt_len_std', 'pkt_len_var', 'fin_flag_cnt', 'syn_flag_cnt', 'rst_flag_cnt', 'psh_flag_cnt', 'ack_flag_cnt', 'urg_flag_cnt', 'cwe_flag_count', 'ece_flag_cnt', 'down_up_ratio', 'pkt_size_avg', 'fwd_seg_size_avg', 'bwd_seg_size_avg', 'fwd_byts_b_avg', 'fwd_pkts_b_avg', 'fwd_blk_rate_avg', 'bwd_byts_b_avg', 'bwd_pkts_b_avg', 'bwd_blk_rate_avg', 'subflow_fwd_pkts', 'subflow_fwd_byts', 'subflow_bwd_pkts', 'subflow_bwd_byts', 'init_fwd_win_byts', 'init_bwd_win_byts', 'fwd_act_data_pkts', 'fwd_seg_size_min', 'active_mean', 'active_std', 'active_max', 'active_min', 'idle_mean', 'idle_std', 'idle_max', 'idle_min']\n",
      "Columns with infinite values: ['flow_byts_s', 'flow_pkts_s']\n",
      "Percentage of NaN values in each column:\n",
      " dst_port           0.000493\n",
      "protocol           0.000493\n",
      "timestamp        100.000000\n",
      "flow_duration      0.000493\n",
      "tot_fwd_pkts       0.000493\n",
      "                    ...    \n",
      "active_min         0.000493\n",
      "idle_mean          0.000493\n",
      "idle_std           0.000493\n",
      "idle_max           0.000493\n",
      "idle_min           0.000493\n",
      "Length: 79, dtype: float64\n",
      "Percentage of infinite values in each column:\n",
      " flow_byts_s    0.219182\n",
      "flow_pkts_s    0.583746\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Select only numeric columns\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "# Identify columns with NaN, infinity, or negative values\n",
    "nan_columns = df[numeric_columns].columns[df[numeric_columns].isna().any()]\n",
    "inf_columns = df[numeric_columns].columns[np.isinf(df[numeric_columns]).any()]\n",
    "print(\"Columns with NaN values:\", nan_columns.tolist())\n",
    "print(\"Columns with infinite values:\", inf_columns.tolist())\n",
    "# Calculate the percentage of NaN, infinite, and negative values\n",
    "nan_percentage = df[nan_columns].isna().mean() * 100\n",
    "# nan_percentage = nan_percentage[nan_percentage > 1]\n",
    "inf_percentage = df[inf_columns].map(lambda x: np.isinf(x)).mean() * 100\n",
    "print(\"Percentage of NaN values in each column:\\n\", nan_percentage)\n",
    "print(\"Percentage of infinite values in each column:\\n\", inf_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d824978-4a2b-4c29-8360-b0cafe84258c",
   "metadata": {},
   "source": [
    "The percentages of rows with infinite or null values are low so the rows are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f69198ca-a213-46b8-afda-7caeb706aedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_invalid(df):\n",
    "    # Select only numeric columns\n",
    "    numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "    # Identify columns with NaN, infinite, or negative values\n",
    "    nan_columns = df[numeric_columns].columns[df[numeric_columns].isna().any()]\n",
    "    inf_columns = df[numeric_columns].columns[np.isinf(df[numeric_columns]).any()]\n",
    "    # Drop rows with NaN values (low percentage of NaN values)\n",
    "    # df = df.dropna(subset=nan_columns)\n",
    "    # Drop rows with infinite values (assuming low percentage)\n",
    "    for col in inf_columns:\n",
    "        df = df[np.isfinite(df[col])]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f2e1e06-278f-4201-ba7d-e58dacfae05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = replace_invalid(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56d795d5-6e48-4f3c-8db0-83af85902e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 0 entries\n",
      "Data columns (total 79 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   dst_port           0 non-null      float64\n",
      " 1   protocol           0 non-null      float64\n",
      " 2   timestamp          0 non-null      float64\n",
      " 3   flow_duration      0 non-null      float64\n",
      " 4   tot_fwd_pkts       0 non-null      float64\n",
      " 5   tot_bwd_pkts       0 non-null      float64\n",
      " 6   totlen_fwd_pkts    0 non-null      float64\n",
      " 7   totlen_bwd_pkts    0 non-null      float64\n",
      " 8   fwd_pkt_len_max    0 non-null      float64\n",
      " 9   fwd_pkt_len_min    0 non-null      float64\n",
      " 10  fwd_pkt_len_mean   0 non-null      float64\n",
      " 11  fwd_pkt_len_std    0 non-null      float64\n",
      " 12  bwd_pkt_len_max    0 non-null      float64\n",
      " 13  bwd_pkt_len_min    0 non-null      float64\n",
      " 14  bwd_pkt_len_mean   0 non-null      float64\n",
      " 15  bwd_pkt_len_std    0 non-null      float64\n",
      " 16  flow_byts_s        0 non-null      float64\n",
      " 17  flow_pkts_s        0 non-null      float64\n",
      " 18  flow_iat_mean      0 non-null      float64\n",
      " 19  flow_iat_std       0 non-null      float64\n",
      " 20  flow_iat_max       0 non-null      float64\n",
      " 21  flow_iat_min       0 non-null      float64\n",
      " 22  fwd_iat_tot        0 non-null      float64\n",
      " 23  fwd_iat_mean       0 non-null      float64\n",
      " 24  fwd_iat_std        0 non-null      float64\n",
      " 25  fwd_iat_max        0 non-null      float64\n",
      " 26  fwd_iat_min        0 non-null      float64\n",
      " 27  bwd_iat_tot        0 non-null      float64\n",
      " 28  bwd_iat_mean       0 non-null      float64\n",
      " 29  bwd_iat_std        0 non-null      float64\n",
      " 30  bwd_iat_max        0 non-null      float64\n",
      " 31  bwd_iat_min        0 non-null      float64\n",
      " 32  fwd_psh_flags      0 non-null      float64\n",
      " 33  bwd_psh_flags      0 non-null      float64\n",
      " 34  fwd_urg_flags      0 non-null      float64\n",
      " 35  bwd_urg_flags      0 non-null      float64\n",
      " 36  fwd_header_len     0 non-null      float64\n",
      " 37  bwd_header_len     0 non-null      float64\n",
      " 38  fwd_pkts_s         0 non-null      float64\n",
      " 39  bwd_pkts_s         0 non-null      float64\n",
      " 40  pkt_len_min        0 non-null      float64\n",
      " 41  pkt_len_max        0 non-null      float64\n",
      " 42  pkt_len_mean       0 non-null      float64\n",
      " 43  pkt_len_std        0 non-null      float64\n",
      " 44  pkt_len_var        0 non-null      float64\n",
      " 45  fin_flag_cnt       0 non-null      float64\n",
      " 46  syn_flag_cnt       0 non-null      float64\n",
      " 47  rst_flag_cnt       0 non-null      float64\n",
      " 48  psh_flag_cnt       0 non-null      float64\n",
      " 49  ack_flag_cnt       0 non-null      float64\n",
      " 50  urg_flag_cnt       0 non-null      float64\n",
      " 51  cwe_flag_count     0 non-null      float64\n",
      " 52  ece_flag_cnt       0 non-null      float64\n",
      " 53  down_up_ratio      0 non-null      float64\n",
      " 54  pkt_size_avg       0 non-null      float64\n",
      " 55  fwd_seg_size_avg   0 non-null      float64\n",
      " 56  bwd_seg_size_avg   0 non-null      float64\n",
      " 57  fwd_byts_b_avg     0 non-null      float64\n",
      " 58  fwd_pkts_b_avg     0 non-null      float64\n",
      " 59  fwd_blk_rate_avg   0 non-null      float64\n",
      " 60  bwd_byts_b_avg     0 non-null      float64\n",
      " 61  bwd_pkts_b_avg     0 non-null      float64\n",
      " 62  bwd_blk_rate_avg   0 non-null      float64\n",
      " 63  subflow_fwd_pkts   0 non-null      float64\n",
      " 64  subflow_fwd_byts   0 non-null      float64\n",
      " 65  subflow_bwd_pkts   0 non-null      float64\n",
      " 66  subflow_bwd_byts   0 non-null      float64\n",
      " 67  init_fwd_win_byts  0 non-null      float64\n",
      " 68  init_bwd_win_byts  0 non-null      float64\n",
      " 69  fwd_act_data_pkts  0 non-null      float64\n",
      " 70  fwd_seg_size_min   0 non-null      float64\n",
      " 71  active_mean        0 non-null      float64\n",
      " 72  active_std         0 non-null      float64\n",
      " 73  active_max         0 non-null      float64\n",
      " 74  active_min         0 non-null      float64\n",
      " 75  idle_mean          0 non-null      float64\n",
      " 76  idle_std           0 non-null      float64\n",
      " 77  idle_max           0 non-null      float64\n",
      " 78  idle_min           0 non-null      float64\n",
      "dtypes: float64(79)\n",
      "memory usage: 0.0 bytes\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 0 entries\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   label       0 non-null      category\n",
      " 1   is_attack   0 non-null      int64   \n",
      " 2   label_code  0 non-null      int32   \n",
      "dtypes: category(1), int32(1), int64(1)\n",
      "memory usage: 684.0 bytes\n",
      "label\n",
      "Benign                      0\n",
      "Bot                         0\n",
      "Brute Force -Web            0\n",
      "Brute Force -XSS            0\n",
      "DDOS attack-HOIC            0\n",
      "DDOS attack-LOIC-UDP        0\n",
      "DDoS attacks-LOIC-HTTP      0\n",
      "DoS attacks-GoldenEye       0\n",
      "DoS attacks-Hulk            0\n",
      "DoS attacks-SlowHTTPTest    0\n",
      "DoS attacks-Slowloris       0\n",
      "FTP-BruteForce              0\n",
      "Infilteration               0\n",
      "Label                       0\n",
      "SQL Injection               0\n",
      "SSH-Bruteforce              0\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:, 0:79]\n",
    "Y = df[[\"label\", \"is_attack\", \"label_code\"]]\n",
    "\n",
    "X.info()\n",
    "Y.info()\n",
    "print(Y.label.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55944397-c544-47ab-948d-2bfd675164df",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f765e7-0ef8-4e12-84e5-6cfebe9ad9c4",
   "metadata": {},
   "source": [
    "First, the columns with no variance are dropped as they have no impact on the target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b019d145-d183-4713-aa0c-407d998c3315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "stats = X.describe()\n",
    "std = stats.loc[\"std\"]\n",
    "features_no_var = std[std == 0.0].index\n",
    "# Exclude non-numeric columns (e.g., categorical columns) from the features with zero variance\n",
    "features_no_var_numeric = [col for col in features_no_var if col in X.select_dtypes(include=[np.number]).columns]\n",
    "print(features_no_var_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dcef2f3-ab5d-4d11-bcaa-653560f4b0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 0 entries\n",
      "Data columns (total 77 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   protocol           0 non-null      float64\n",
      " 1   flow_duration      0 non-null      float64\n",
      " 2   tot_fwd_pkts       0 non-null      float64\n",
      " 3   tot_bwd_pkts       0 non-null      float64\n",
      " 4   totlen_fwd_pkts    0 non-null      float64\n",
      " 5   totlen_bwd_pkts    0 non-null      float64\n",
      " 6   fwd_pkt_len_max    0 non-null      float64\n",
      " 7   fwd_pkt_len_min    0 non-null      float64\n",
      " 8   fwd_pkt_len_mean   0 non-null      float64\n",
      " 9   fwd_pkt_len_std    0 non-null      float64\n",
      " 10  bwd_pkt_len_max    0 non-null      float64\n",
      " 11  bwd_pkt_len_min    0 non-null      float64\n",
      " 12  bwd_pkt_len_mean   0 non-null      float64\n",
      " 13  bwd_pkt_len_std    0 non-null      float64\n",
      " 14  flow_byts_s        0 non-null      float64\n",
      " 15  flow_pkts_s        0 non-null      float64\n",
      " 16  flow_iat_mean      0 non-null      float64\n",
      " 17  flow_iat_std       0 non-null      float64\n",
      " 18  flow_iat_max       0 non-null      float64\n",
      " 19  flow_iat_min       0 non-null      float64\n",
      " 20  fwd_iat_tot        0 non-null      float64\n",
      " 21  fwd_iat_mean       0 non-null      float64\n",
      " 22  fwd_iat_std        0 non-null      float64\n",
      " 23  fwd_iat_max        0 non-null      float64\n",
      " 24  fwd_iat_min        0 non-null      float64\n",
      " 25  bwd_iat_tot        0 non-null      float64\n",
      " 26  bwd_iat_mean       0 non-null      float64\n",
      " 27  bwd_iat_std        0 non-null      float64\n",
      " 28  bwd_iat_max        0 non-null      float64\n",
      " 29  bwd_iat_min        0 non-null      float64\n",
      " 30  fwd_psh_flags      0 non-null      float64\n",
      " 31  bwd_psh_flags      0 non-null      float64\n",
      " 32  fwd_urg_flags      0 non-null      float64\n",
      " 33  bwd_urg_flags      0 non-null      float64\n",
      " 34  fwd_header_len     0 non-null      float64\n",
      " 35  bwd_header_len     0 non-null      float64\n",
      " 36  fwd_pkts_s         0 non-null      float64\n",
      " 37  bwd_pkts_s         0 non-null      float64\n",
      " 38  pkt_len_min        0 non-null      float64\n",
      " 39  pkt_len_max        0 non-null      float64\n",
      " 40  pkt_len_mean       0 non-null      float64\n",
      " 41  pkt_len_std        0 non-null      float64\n",
      " 42  pkt_len_var        0 non-null      float64\n",
      " 43  fin_flag_cnt       0 non-null      float64\n",
      " 44  syn_flag_cnt       0 non-null      float64\n",
      " 45  rst_flag_cnt       0 non-null      float64\n",
      " 46  psh_flag_cnt       0 non-null      float64\n",
      " 47  ack_flag_cnt       0 non-null      float64\n",
      " 48  urg_flag_cnt       0 non-null      float64\n",
      " 49  cwe_flag_count     0 non-null      float64\n",
      " 50  ece_flag_cnt       0 non-null      float64\n",
      " 51  down_up_ratio      0 non-null      float64\n",
      " 52  pkt_size_avg       0 non-null      float64\n",
      " 53  fwd_seg_size_avg   0 non-null      float64\n",
      " 54  bwd_seg_size_avg   0 non-null      float64\n",
      " 55  fwd_byts_b_avg     0 non-null      float64\n",
      " 56  fwd_pkts_b_avg     0 non-null      float64\n",
      " 57  fwd_blk_rate_avg   0 non-null      float64\n",
      " 58  bwd_byts_b_avg     0 non-null      float64\n",
      " 59  bwd_pkts_b_avg     0 non-null      float64\n",
      " 60  bwd_blk_rate_avg   0 non-null      float64\n",
      " 61  subflow_fwd_pkts   0 non-null      float64\n",
      " 62  subflow_fwd_byts   0 non-null      float64\n",
      " 63  subflow_bwd_pkts   0 non-null      float64\n",
      " 64  subflow_bwd_byts   0 non-null      float64\n",
      " 65  init_fwd_win_byts  0 non-null      float64\n",
      " 66  init_bwd_win_byts  0 non-null      float64\n",
      " 67  fwd_act_data_pkts  0 non-null      float64\n",
      " 68  fwd_seg_size_min   0 non-null      float64\n",
      " 69  active_mean        0 non-null      float64\n",
      " 70  active_std         0 non-null      float64\n",
      " 71  active_max         0 non-null      float64\n",
      " 72  active_min         0 non-null      float64\n",
      " 73  idle_mean          0 non-null      float64\n",
      " 74  idle_std           0 non-null      float64\n",
      " 75  idle_max           0 non-null      float64\n",
      " 76  idle_min           0 non-null      float64\n",
      "dtypes: float64(77)\n",
      "memory usage: 0.0 bytes\n"
     ]
    }
   ],
   "source": [
    "X = X.drop(columns=features_no_var)\n",
    "X = X.drop(columns=['dst_port', 'timestamp'])\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d20f95-d408-422b-a05f-f55be30867c2",
   "metadata": {},
   "source": [
    "### Remove collinear variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b3aa477-0958-48bb-9b33-3e234e0ce040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 0 entries\n",
      "Data columns (total 77 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   protocol           0 non-null      float64\n",
      " 1   flow_duration      0 non-null      float64\n",
      " 2   tot_fwd_pkts       0 non-null      float64\n",
      " 3   tot_bwd_pkts       0 non-null      float64\n",
      " 4   totlen_fwd_pkts    0 non-null      float64\n",
      " 5   totlen_bwd_pkts    0 non-null      float64\n",
      " 6   fwd_pkt_len_max    0 non-null      float64\n",
      " 7   fwd_pkt_len_min    0 non-null      float64\n",
      " 8   fwd_pkt_len_mean   0 non-null      float64\n",
      " 9   fwd_pkt_len_std    0 non-null      float64\n",
      " 10  bwd_pkt_len_max    0 non-null      float64\n",
      " 11  bwd_pkt_len_min    0 non-null      float64\n",
      " 12  bwd_pkt_len_mean   0 non-null      float64\n",
      " 13  bwd_pkt_len_std    0 non-null      float64\n",
      " 14  flow_byts_s        0 non-null      float64\n",
      " 15  flow_pkts_s        0 non-null      float64\n",
      " 16  flow_iat_mean      0 non-null      float64\n",
      " 17  flow_iat_std       0 non-null      float64\n",
      " 18  flow_iat_max       0 non-null      float64\n",
      " 19  flow_iat_min       0 non-null      float64\n",
      " 20  fwd_iat_tot        0 non-null      float64\n",
      " 21  fwd_iat_mean       0 non-null      float64\n",
      " 22  fwd_iat_std        0 non-null      float64\n",
      " 23  fwd_iat_max        0 non-null      float64\n",
      " 24  fwd_iat_min        0 non-null      float64\n",
      " 25  bwd_iat_tot        0 non-null      float64\n",
      " 26  bwd_iat_mean       0 non-null      float64\n",
      " 27  bwd_iat_std        0 non-null      float64\n",
      " 28  bwd_iat_max        0 non-null      float64\n",
      " 29  bwd_iat_min        0 non-null      float64\n",
      " 30  fwd_psh_flags      0 non-null      float64\n",
      " 31  bwd_psh_flags      0 non-null      float64\n",
      " 32  fwd_urg_flags      0 non-null      float64\n",
      " 33  bwd_urg_flags      0 non-null      float64\n",
      " 34  fwd_header_len     0 non-null      float64\n",
      " 35  bwd_header_len     0 non-null      float64\n",
      " 36  fwd_pkts_s         0 non-null      float64\n",
      " 37  bwd_pkts_s         0 non-null      float64\n",
      " 38  pkt_len_min        0 non-null      float64\n",
      " 39  pkt_len_max        0 non-null      float64\n",
      " 40  pkt_len_mean       0 non-null      float64\n",
      " 41  pkt_len_std        0 non-null      float64\n",
      " 42  pkt_len_var        0 non-null      float64\n",
      " 43  fin_flag_cnt       0 non-null      float64\n",
      " 44  syn_flag_cnt       0 non-null      float64\n",
      " 45  rst_flag_cnt       0 non-null      float64\n",
      " 46  psh_flag_cnt       0 non-null      float64\n",
      " 47  ack_flag_cnt       0 non-null      float64\n",
      " 48  urg_flag_cnt       0 non-null      float64\n",
      " 49  cwe_flag_count     0 non-null      float64\n",
      " 50  ece_flag_cnt       0 non-null      float64\n",
      " 51  down_up_ratio      0 non-null      float64\n",
      " 52  pkt_size_avg       0 non-null      float64\n",
      " 53  fwd_seg_size_avg   0 non-null      float64\n",
      " 54  bwd_seg_size_avg   0 non-null      float64\n",
      " 55  fwd_byts_b_avg     0 non-null      float64\n",
      " 56  fwd_pkts_b_avg     0 non-null      float64\n",
      " 57  fwd_blk_rate_avg   0 non-null      float64\n",
      " 58  bwd_byts_b_avg     0 non-null      float64\n",
      " 59  bwd_pkts_b_avg     0 non-null      float64\n",
      " 60  bwd_blk_rate_avg   0 non-null      float64\n",
      " 61  subflow_fwd_pkts   0 non-null      float64\n",
      " 62  subflow_fwd_byts   0 non-null      float64\n",
      " 63  subflow_bwd_pkts   0 non-null      float64\n",
      " 64  subflow_bwd_byts   0 non-null      float64\n",
      " 65  init_fwd_win_byts  0 non-null      float64\n",
      " 66  init_bwd_win_byts  0 non-null      float64\n",
      " 67  fwd_act_data_pkts  0 non-null      float64\n",
      " 68  fwd_seg_size_min   0 non-null      float64\n",
      " 69  active_mean        0 non-null      float64\n",
      " 70  active_std         0 non-null      float64\n",
      " 71  active_max         0 non-null      float64\n",
      " 72  active_min         0 non-null      float64\n",
      " 73  idle_mean          0 non-null      float64\n",
      " 74  idle_std           0 non-null      float64\n",
      " 75  idle_max           0 non-null      float64\n",
      " 76  idle_min           0 non-null      float64\n",
      "dtypes: float64(77)\n",
      "memory usage: 0.0 bytes\n"
     ]
    }
   ],
   "source": [
    "def correlation_feature_selection(df, threshold=0.95):\n",
    "    corr_matrix = df.corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "    return df.drop(columns=to_drop)\n",
    "X = correlation_feature_selection(X)\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e99c33-2909-42c7-bf5d-1f18597b7294",
   "metadata": {},
   "source": [
    "### Information Gain Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7c9f4e8-af3d-4eed-afa6-e3287074ab62",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m selected_features\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Determine the selected features using the oversampled subset\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m selected_features \u001b[38;5;241m=\u001b[39m \u001b[43minformation_gain_feature_selection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Apply the selected features to the main dataset\u001b[39;00m\n\u001b[0;32m     30\u001b[0m X \u001b[38;5;241m=\u001b[39m X[selected_features]\n",
      "Cell \u001b[1;32mIn[9], line 15\u001b[0m, in \u001b[0;36minformation_gain_feature_selection\u001b[1;34m(X, Y, sample_size)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minformation_gain_feature_selection\u001b[39m(X, Y, sample_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m):\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# Create an oversampled subset of the data\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     X_sample, y_sample \u001b[38;5;241m=\u001b[39m \u001b[43moversample_minority_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# Create is_attack column based on label_code\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     y_sample \u001b[38;5;241m=\u001b[39m (y_sample \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "Cell \u001b[1;32mIn[9], line 8\u001b[0m, in \u001b[0;36moversample_minority_classes\u001b[1;34m(X, Y, sample_size)\u001b[0m\n\u001b[0;32m      6\u001b[0m y\u001b[38;5;241m=\u001b[39mY[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel_code\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      7\u001b[0m ros \u001b[38;5;241m=\u001b[39m RandomOverSampler(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m X_resampled, y_resampled \u001b[38;5;241m=\u001b[39m \u001b[43mros\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Create a subset of the oversampled data\u001b[39;00m\n\u001b[0;32m     10\u001b[0m X_sample, _, y_sample, _ \u001b[38;5;241m=\u001b[39m train_test_split(X_resampled, y_resampled, train_size\u001b[38;5;241m=\u001b[39msample_size, stratify\u001b[38;5;241m=\u001b[39my_resampled, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\imblearn\\base.py:208\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\imblearn\\base.py:106\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    104\u001b[0m check_classification_targets(y)\n\u001b[0;32m    105\u001b[0m arrays_transformer \u001b[38;5;241m=\u001b[39m ArraysTransformer(X, y)\n\u001b[1;32m--> 106\u001b[0m X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m check_sampling_strategy(\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampling_type\n\u001b[0;32m    110\u001b[0m )\n\u001b[0;32m    112\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_resample(X, y)\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\imblearn\\over_sampling\\_random_over_sampler.py:158\u001b[0m, in \u001b[0;36mRandomOverSampler._check_X_y\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_X_y\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[0;32m    157\u001b[0m     y, binarize_y \u001b[38;5;241m=\u001b[39m check_target_type(y, indicate_one_vs_all\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 158\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43m_check_X\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_feature_names(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\imblearn\\utils\\_validation.py:639\u001b[0m, in \u001b[0;36m_check_X\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m    637\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(X)\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 639\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    640\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m sample(s) while a minimum of 1 is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequired.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    642\u001b[0m     )\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_pandas_df(X):\n\u001b[0;32m    644\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "def oversample_minority_classes(X, Y, sample_size=1000):\n",
    "    y=Y[\"label_code\"]\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "    # Create a subset of the oversampled data\n",
    "    X_sample, _, y_sample, _ = train_test_split(X_resampled, y_resampled, train_size=sample_size, stratify=y_resampled, random_state=42)\n",
    "    return X_sample, y_sample\n",
    "\n",
    "def information_gain_feature_selection(X, Y, sample_size=1000):\n",
    "    # Create an oversampled subset of the data\n",
    "    X_sample, y_sample = oversample_minority_classes(X, Y, sample_size)\n",
    "    # Create is_attack column based on label_code\n",
    "    y_sample = (y_sample != 0).astype(int)\n",
    "    # Perform feature selection on the oversampled subset\n",
    "    info_gain = mutual_info_classif(X_sample, y_sample)\n",
    "    info_gain_df = pd.DataFrame({'Feature': X.columns, 'Information Gain': info_gain})\n",
    "    info_gain_df = info_gain_df.sort_values(by='Information Gain', ascending=False)\n",
    "    print(info_gain_df)\n",
    "    selected_features = info_gain_df[info_gain_df['Information Gain'] > 0]['Feature'].tolist()\n",
    "    return selected_features\n",
    "\n",
    "# Determine the selected features using the oversampled subset\n",
    "selected_features = information_gain_feature_selection(X, Y)\n",
    "\n",
    "# Apply the selected features to the main dataset\n",
    "X = X[selected_features]\n",
    "\n",
    "# Display information about the selected features\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b0c52f-ea33-45a7-8db2-064f5dda2853",
   "metadata": {},
   "source": [
    "## Split Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c656b6ac-c354-4cd5-8681-24cd9328fc56",
   "metadata": {},
   "source": [
    "The dataset is split into a training set and a testing set with a ratio of 0.8/0.2. The dataset is stratified according to the label to have an equal representation of all classes in the 2 subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a78694-d174-4633-a7a2-bc3b1b4349a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, stratify=Y.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9e2fc9-7fe8-4df5-8d5d-7ebf68141397",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ba2cfa-3f69-43c2-8a63-2d7c2125a931",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8ed264-63d7-4197-a4da-a3b60c362dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_percentage = len(Y_train.label[Y_train[\"label\"]==\"BENIGN\"])/len(Y_train)\n",
    "print('Percentage of benign samples: %.4f' % benign_percentage)\n",
    "print(Y_train.is_attack.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f731bff-0a2c-41e6-9b34-e12dab60b40f",
   "metadata": {},
   "source": [
    "## Machine Learning Classifiers with Default Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a77eb4a-d54c-4a74-a02a-008fe229c5c9",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b69305d-0026-4c84-afc7-882acfde8f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "def save_model(model, model_name):\n",
    "    file_path = f'models/{model_name}.pkl'\n",
    "    joblib.dump(model, file_path)\n",
    "    print(f'Model saved to {file_path}')\n",
    "\n",
    "def load_model(model_name):\n",
    "    file_path = f'models/{model_name}.pkl'\n",
    "    model = joblib.load(file_path)\n",
    "    print(f'Model loaded from {file_path}')\n",
    "    return model\n",
    "\n",
    "os.makedirs('models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8552768-75ee-48df-9b2a-1e5c0c1ddad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(model_name, Y_true, Y_pred, labels=[\"Benign\", \"Attack\"]):\n",
    "    matrix = confusion_matrix(Y_true.is_attack, Y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(matrix, annot=True, cmap='Blues', fmt='d', xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(f'Confusion Matrix for {model_name}')\n",
    "    plt.show()\n",
    "\n",
    "def metrics_report(dataset_type, y_true, y_predict, print_avg=True):\n",
    "    print(f\"Classification Report ({dataset_type}):\")\n",
    "    print(classification_report(y_true, y_predict, digits=4))\n",
    "    accuracy = accuracy_score(y_true, y_predict)\n",
    "    precision = precision_score(y_true, y_predict, average='weighted')\n",
    "    recall = recall_score(y_true, y_predict, average='weighted')\n",
    "    f1 = f1_score(y_true, y_predict, average='weighted')\n",
    "    auc = roc_auc_score(y_true, y_predict)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"AUC:\", auc)\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1, \"auc\": auc}\n",
    "\n",
    "def calculate_metrics_by_label(y_true, y_pred, labels):\n",
    "    results = []\n",
    "    unique_labels = labels.unique()\n",
    "    for label in unique_labels:\n",
    "        indices = labels == label\n",
    "        accuracy = accuracy_score(y_true[indices], y_pred[indices])\n",
    "        results.append({\n",
    "            'Label': label,\n",
    "            'Accuracy': accuracy,\n",
    "        })\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199bdba3-37c1-4a27-8a85-58063d44a413",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_metrics(model_name, model, dataset_type, scaler):\n",
    "    # Predict and evaluate on the test set\n",
    "    print(f\"{model_name} with {dataset_type} Test Set Performance\")\n",
    "    Y_pred = model.predict(scaler.transform(X_test))\n",
    "    metrics = metrics_report(f\"Test {model_name} ({dataset_type})\", Y_test.is_attack, Y_pred)\n",
    "    plot_confusion_matrix(f\"{model_name} ({dataset_type})\", Y_test, Y_pred)\n",
    "    # Calculate metrics by label\n",
    "    metrics_by_label = calculate_metrics_by_label(Y_test.is_attack, Y_pred, Y_test.label)\n",
    "    metrics_by_label['Method'] = dataset_type\n",
    "    print(f\"Metrics by Label ({dataset_type}):\")\n",
    "    print(metrics_by_label)\n",
    "    return metrics, metrics_by_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d755a9-a452-4c3e-8a1e-5318521d9463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_overall_accuracy(metrics):\n",
    "    methods = ['original', 'random', 'smote', 'adasyn']\n",
    "    overall_accuracies = []\n",
    "\n",
    "    # Extract overall accuracy for each method\n",
    "    for method in methods:\n",
    "        overall_accuracies.append(metrics[method][0]['accuracy'])\n",
    "\n",
    "    # Plotting the overall accuracies\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(methods, overall_accuracies, color=['blue', 'orange', 'green', 'red'])\n",
    "    plt.title('Overall Accuracy by Method')\n",
    "    plt.xlabel('Method')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim(0.9, 1)\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Display the values on each bar\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2.0, yval, f'{yval:.3f}', ha='center', va='bottom')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ca1347-9229-4744-a9c7-ddde1c2f3bc8",
   "metadata": {},
   "source": [
    "### Resampling methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8316ca1b-a2a1-49fe-9888-3fe5f80a2bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "\n",
    "def resample_dataset(X, Y, min_samples, attack_labels, technique='smote'):\n",
    "    Y = Y.drop(columns=['label'])\n",
    "    combined = pd.concat([X, Y], axis=1)\n",
    "    counts = Y['label_code'].value_counts()\n",
    "    samples_number = {i: max(counts[i], min_samples) for i in np.unique(Y['label_code'])}\n",
    "    combined_array = combined.values\n",
    "    y_array = Y['label_code'].values\n",
    "\n",
    "    if technique == 'random':\n",
    "        resampler = RandomOverSampler(random_state=42, sampling_strategy=samples_number)\n",
    "    elif technique == 'smote':\n",
    "        resampler = SMOTE(random_state=42, sampling_strategy=samples_number, k_neighbors=5)\n",
    "    elif technique == 'adasyn':\n",
    "        resampler = ADASYN(random_state=42, sampling_strategy=samples_number)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid resampling technique. Choose 'random', 'smote', or 'adasyn'.\")\n",
    "\n",
    "    resampled_array, y_resampled = resampler.fit_resample(combined_array, y_array)\n",
    "    X_resampled = resampled_array[:, :-Y.shape[1]]\n",
    "    Y_resampled = resampled_array[:, -Y.shape[1]:]\n",
    "    X_resampled_df = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "    Y_resampled_df = pd.DataFrame(Y_resampled, columns=Y.columns)\n",
    "    Y_resampled_df['label'] = Y_resampled_df['label_code'].map(attack_labels)\n",
    "    Y_resampled_df['label'] = Y_resampled_df['label'].astype('category')\n",
    "    return X_resampled_df, Y_resampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02f4dfe-607f-447f-9d8f-b0c2349771e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_random_train, Y_random_train = resample_dataset(X_train, Y_train, 100000, attack_labels, \"random\")\n",
    "X_smote_train, Y_smote_train = resample_dataset(X_train, Y_train, 100000, attack_labels, \"smote\")\n",
    "X_adasyn_train, Y_adasyn_train = resample_dataset(X_train, Y_train, 100000, attack_labels, \"adasyn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87cffe0-4d59-4baa-813f-7a1acc34c490",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4578f622-8c14-4de5-8823-e400d914109f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_random_train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c25904-4cf1-4f57-9f2e-4c108ea64b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_smote_train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a71a12-31b6-435d-b305-a5a94ecd73da",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_adasyn_train.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d680062e-9c73-4479-a97a-0af35527d672",
   "metadata": {},
   "source": [
    "### Scaling with the Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a16fb4-ebec-454f-a7af-92979f3662d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original X_train\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "# Random Oversampling\n",
    "scaler_random = StandardScaler()\n",
    "scaler_random.fit(X_random_train)\n",
    "# SMOTE\n",
    "scaler_smote = StandardScaler()\n",
    "scaler_smote.fit(X_smote_train)\n",
    "# ADASYN\n",
    "scaler_adasyn = StandardScaler()\n",
    "scaler_adasyn.fit(X_adasyn_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510f7e75-3495-4a7c-9f8d-9344d2b5c2eb",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c793abbc-55d7-4e41-8d43-38a371bf7797",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_metrics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a9dcb4-e125-4a13-966f-184d02edbf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_model = DecisionTreeClassifier()\n",
    "decision_tree_model.fit(scaler.transform(X_train), Y_train.is_attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813fcad0-1c82-494a-8c6d-5f14f6cd1ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and evaluate on the test set\n",
    "dt_metrics[\"original\"] = test_metrics(\"Decision Tree\", decision_tree_model, \"Original\", scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f74d555-7d69-499e-91f4-cbb400e23e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_model_random = DecisionTreeClassifier()\n",
    "decision_tree_model_random.fit(scaler_random.transform(X_random_train), Y_random_train.is_attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651d96dd-ed97-49a7-9241-ae9d0caddbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and evaluate on the test set\n",
    "dt_metrics[\"random\"] = test_metrics(\"Decision Tree\", decision_tree_model_random, \"Random Oversampling\", scaler_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032ed93f-2e9d-43e6-b954-4ca98d2ddbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_model_smote = DecisionTreeClassifier()\n",
    "decision_tree_model_smote.fit(scaler_smote.transform(X_smote_train), Y_smote_train.is_attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f994fc-0505-4737-805c-f6b2e8e6f472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and evaluate on the test set\n",
    "dt_metrics[\"smote\"] = test_metrics(\"Decision Tree\", decision_tree_model_smote, \"SMOTE\", scaler_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb76600-d604-4431-9c2b-e9d2dd13f093",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_model_adasyn = DecisionTreeClassifier()\n",
    "decision_tree_model_adasyn.fit(scaler_adasyn.transform(X_adasyn_train), Y_adasyn_train.is_attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b311617-d99c-4b53-83ec-026072d893c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and evaluate on the test set\n",
    "dt_metrics[\"adasyn\"] = test_metrics(\"Decision Tree\", decision_tree_model_adasyn, \"ADASYN\", scaler_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb36e228-ac70-4657-9f6d-d5068115a718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine metrics into one DataFrame for Decision Tree\n",
    "combined_metrics_dt = pd.concat([dt_metrics[\"adasyn\"][1], dt_metrics[\"original\"][1], dt_metrics[\"random\"][1], dt_metrics[\"smote\"][1]])\n",
    "# Pivot the table to get accuracy for each method as columns in the specified order\n",
    "accuracy_pivot_dt = combined_metrics_dt.pivot(index='Label', columns='Method', values='Accuracy')\n",
    "accuracy_pivot_dt = accuracy_pivot_dt[['Original', 'Random Oversampling', 'SMOTE', 'ADASYN']]\n",
    "print(\"Accuracy by Label and Method (Decision Tree):\")\n",
    "print(accuracy_pivot_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acc3931-e0a5-4f57-8a7a-1182ffe8e8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_overall_accuracy(dt_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3660e525-cfbc-43b2-875f-74ae3703ffde",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc40317-b2ed-4ad4-b7f7-0dc01b616686",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_metrics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3ca2c5-f7f2-40f6-b492-93870bcc2160",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(verbose=1, n_jobs=-1)\n",
    "rf_model.fit(scaler.transform(X_train), Y_train.is_attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc74aee-ac26-4dbd-84a1-0068827a0d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and evaluate on the test set\n",
    "rf_metrics[\"original\"] = test_metrics(\"Random Forest\", rf_model, \"Original\", scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2c331f-47ea-4049-a9c5-4f0dc9559513",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_random = RandomForestClassifier(verbose=1, n_jobs=-1)\n",
    "rf_model_random.fit(scaler_random.transform(X_random_train), Y_random_train.is_attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde030f7-bbb4-4388-a427-1664628e3c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and evaluate on the test set\n",
    "rf_metrics[\"random\"] = test_metrics(\"Random Forest\", rf_model_random, \"Random Oversampling\", scaler_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b751711f-735c-4441-af62-564dabcc2d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_smote = RandomForestClassifier(verbose=1, n_jobs=-1)\n",
    "rf_model_smote.fit(scaler_smote.transform(X_smote_train), Y_smote_train.is_attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de74e5a8-09e4-4db5-af5e-9025bae6a144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and evaluate on the test set\n",
    "rf_metrics[\"smote\"] = test_metrics(\"Random Forest\", rf_model_smote, \"SMOTE\", scaler_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184a32e5-fe40-46b8-ad1a-8d1c951a6ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_adasyn = RandomForestClassifier(verbose=1, n_jobs=-1)\n",
    "rf_model_adasyn.fit(scaler_adasyn.transform(X_adasyn_train), Y_adasyn_train.is_attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8afe6d-d049-41a4-b38b-454291c13373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and evaluate on the test set\n",
    "rf_metrics[\"adasyn\"] = test_metrics(\"Random Forest\", rf_model_adasyn, \"ADASYN\", scaler_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3828c4cf-2874-4ac9-9805-cc1b1b5c42a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine metrics into one DataFrame\n",
    "combined_metrics_rf = pd.concat([rf_metrics[\"adasyn\"][1], rf_metrics[\"original\"][1], rf_metrics[\"random\"][1], rf_metrics[\"smote\"][1]])\n",
    "# Pivot the table to get accuracy for each method as columns in the specified order\n",
    "accuracy_pivot_rf = combined_metrics_rf.pivot(index='Label', columns='Method', values='Accuracy')\n",
    "accuracy_pivot_rf = accuracy_pivot_rf[['Original', 'Random Oversampling', 'SMOTE', 'ADASYN']]\n",
    "print(\"Accuracy by Label and Method:\")\n",
    "print(accuracy_pivot_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3e3b40-f450-454b-8453-a864955a0ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_overall_accuracy(rf_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa7af76-3150-4568-92f8-a0efae323494",
   "metadata": {},
   "source": [
    "### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8892adb-0df3-49fe-ac0a-b25dff8586ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_metrics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4420e970-9b8d-4b05-9749-451234f45a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_model = AdaBoostClassifier(algorithm='SAMME')\n",
    "ada_model.fit(scaler.transform(X_train), Y_train.is_attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4a74a0-d6e8-43fa-bad3-b6414973347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and evaluate on the test set\n",
    "ada_metrics[\"original\"] = test_metrics(\"AdaBoost\", ada_model, \"Original\", scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8838fd6c-0a82-4752-a76f-e5eef9de4f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_model_random = AdaBoostClassifier(algorithm='SAMME')\n",
    "ada_model_random.fit(scaler_random.transform(X_random_train), Y_random_train.is_attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65f9c36-012a-4227-a56d-083950432d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and evaluate on the test set\n",
    "ada_metrics[\"random\"] = test_metrics(\"AdaBoost\", ada_model_random, \"Random Oversampling\", scaler_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc11f2c8-84a3-484a-9075-a84935ce173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_model_smote = AdaBoostClassifier(algorithm='SAMME')\n",
    "ada_model_smote.fit(scaler_smote.transform(X_smote_train), Y_smote_train.is_attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22b795e-69e4-4e4c-87f4-90b416b534b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and evaluate on the test set\n",
    "ada_metrics[\"smote\"] = test_metrics(\"AdaBoost\", ada_model_smote, \"SMOTE\", scaler_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855676c2-f109-48a6-9f83-32069bd9b58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_model_adasyn = AdaBoostClassifier(algorithm='SAMME')\n",
    "ada_model_adasyn.fit(scaler_adasyn.transform(X_adasyn_train), Y_adasyn_train.is_attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad112c0f-3ee8-4228-963d-55dd138ba8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and evaluate on the test set\n",
    "ada_metrics[\"adasyn\"] = test_metrics(\"AdaBoost\", ada_model_adasyn, \"ADASYN\", scaler_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57de8db0-c16f-4ca6-ab11-444ea006128f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine metrics into one DataFrame\n",
    "combined_metrics_ada = pd.concat([ada_metrics[\"adasyn\"][1], ada_metrics[\"original\"][1], ada_metrics[\"random\"][1], ada_metrics[\"smote\"][1]])\n",
    "\n",
    "# Pivot the table to get accuracy for each method as columns in the specified order\n",
    "accuracy_pivot_ada = combined_metrics_ada.pivot(index='Label', columns='Method', values='Accuracy')\n",
    "accuracy_pivot_ada = accuracy_pivot_ada[['Original', 'Random Oversampling', 'SMOTE', 'ADASYN']]\n",
    "print(\"Accuracy by Label and Method (AdaBoost):\")\n",
    "print(accuracy_pivot_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e326581d-eb11-4af2-8340-e4a72ce6a688",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_overall_accuracy(ada_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec52285-f1b0-413e-b731-23efab38607e",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b12a51-c6ec-43a6-bdb6-f3cb270f99be",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_metrics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fad2586-2487-4018-bedf-c4dd4fdc2837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(n_jobs=-1)\n",
    "xgb_model.fit(scaler.transform(X_train), Y_train.is_attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77513a06-ec95-4b21-962f-f0d8cb9a657c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and evaluate on the test set\n",
    "# Original Dataset\n",
    "xgb_metrics[\"original\"] = test_metrics(\"XGBoost\", xgb_model, \"Original\", scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8fba95-7ef9-47b3-9479-6de6783579f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model_random = xgb.XGBClassifier(n_jobs=-1)\n",
    "xgb_model_random.fit(scaler_random.transform(X_random_train), Y_random_train.is_attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a2e79c-40bd-4f48-a2fd-596e457c0a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and evaluate on the test set\n",
    "# Random Oversampling\n",
    "xgb_metrics[\"random\"] = test_metrics(\"XGBoost\", xgb_model_random, \"Random Oversampling\", scaler_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303abb6f-6257-475d-a875-6ea40409a468",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model_smote = xgb.XGBClassifier(n_jobs=-1)\n",
    "xgb_model_smote.fit(scaler_smote.transform(X_smote_train), Y_smote_train.is_attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415b0751-b981-4876-8868-8182f6f31471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and evaluate on the test set\n",
    "# SMOTE\n",
    "xgb_metrics[\"smote\"] = test_metrics(\"XGBoost\", xgb_model_smote, \"SMOTE\", scaler_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5c92d7-6a52-4f04-8969-07446a530045",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model_adasyn = xgb.XGBClassifier(n_jobs=-1)\n",
    "xgb_model_adasyn.fit(scaler_adasyn.transform(X_adasyn_train), Y_adasyn_train.is_attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c7fe7a-3dc3-482f-a044-d2bca81b2a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and evaluate on the test set\n",
    "# ADASYN\n",
    "xgb_metrics[\"adasyn\"] = test_metrics(\"XGBoost\", xgb_model_adasyn, \"ADASYN\", scaler_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc5c577-c665-40d4-98ac-d877c907fafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine metrics into one DataFrame\n",
    "combined_metrics_xgb = pd.concat([xgb_metrics[\"adasyn\"][1], xgb_metrics[\"original\"][1], xgb_metrics[\"random\"][1], xgb_metrics[\"smote\"][1]])\n",
    "# Pivot the table to get accuracy for each method as columns in the specified order\n",
    "accuracy_pivot_xgb = combined_metrics_xgb.pivot(index='Label', columns='Method', values='Accuracy')\n",
    "accuracy_pivot_xgb = accuracy_pivot_xgb[['Original', 'Random Oversampling', 'SMOTE', 'ADASYN']]\n",
    "print(\"Accuracy by Label and Method:\")\n",
    "print(accuracy_pivot_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26893c73-24d2-4189-8d90-814b297be23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_overall_accuracy(xgb_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
