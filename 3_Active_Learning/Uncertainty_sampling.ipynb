{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1689b284-251f-470a-acb6-b8571b72f813",
   "metadata": {},
   "source": [
    "# Active Learning with Uncertainty Sampling on the IDS2017"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11365225-e14e-48ba-827b-e1b90e397d57",
   "metadata": {},
   "source": [
    "In this notebook, an active learning approach is used to progressively learn to detect attacks in the IDS2017 with a partially labelled dataset leveragin uncertainty sampling. The fully labeled dataset is used to simulate a human oracle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7da7e12b-2271-423e-81a8-b3375934fa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import os\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, average_precision_score, make_scorer, precision_score, accuracy_score, confusion_matrix, recall_score, f1_score, roc_auc_score\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "file_path = r\"..\\CIC-IDS-2017\\CSVs\\GeneratedLabelledFlows\\TrafficLabelling\\processed\\ids2017_processed.csv\"\n",
    "\n",
    "def load_dataset(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    convert_dict = {'label': 'category'}\n",
    "    df = df.astype(convert_dict)\n",
    "    df['id'] = df.index\n",
    "    df.info()\n",
    "    return df\n",
    "\n",
    "attack_labels = {\n",
    "    0: 'BENIGN',\n",
    "    7: 'FTP-Patator',\n",
    "    11: 'SSH-Patator',\n",
    "    6: 'DoS slowloris',\n",
    "    5: 'DoS Slowhttptest',\n",
    "    4: 'DoS Hulk',\n",
    "    3: 'DoS GoldenEye',\n",
    "    8: 'Heartbleed',\n",
    "    12: 'Web Attack - Brute Force',\n",
    "    14: 'Web Attack - XSS',\n",
    "    13: 'Web Attack - Sql Injection',\n",
    "    9: 'Infiltration',\n",
    "    1: 'Bot',\n",
    "    10: 'PortScan',\n",
    "    2: 'DDoS'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18c6e299-88ab-4d6c-8f04-e3ab4d4be2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Function to resample dataset using SMOTE\n",
    "def resample_dataset(X, Y, min_samples, attack_labels):\n",
    "    Y = Y.drop(columns=['label'])  # Exclude 'label' from Y\n",
    "    combined = pd.concat([X, Y], axis=1)\n",
    "    counts = Y['label_code'].value_counts()\n",
    "    samples_number = {i: max(counts[i], min_samples) for i in np.unique(Y['label_code'])}\n",
    "    combined_array = combined.values\n",
    "    y_array = Y['label_code'].values\n",
    "    resampler = SMOTE(random_state=42, sampling_strategy=samples_number)\n",
    "    resampled_array, y_resampled = resampler.fit_resample(combined_array, y_array)\n",
    "    X_resampled = resampled_array[:, :-Y.shape[1]]\n",
    "    Y_resampled = resampled_array[:, -Y.shape[1]:]\n",
    "    X_resampled_df = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "    Y_resampled_df = pd.DataFrame(Y_resampled, columns=Y.columns)\n",
    "    Y_resampled_df['label'] = Y_resampled_df['label_code'].map(attack_labels)\n",
    "    Y_resampled_df['label'] = Y_resampled_df['label'].astype('category')\n",
    "    return X_resampled_df, Y_resampled_df\n",
    "\n",
    "# Function to dynamically calculate the minimum number of samples for SMOTE\n",
    "def calculate_min_samples(labeled_data, base_ratio=0.1, min_value=1000):\n",
    "    # Calculate the minimum number of samples as a percentage of the labeled data\n",
    "    num_samples = max(int(len(labeled_data) * base_ratio), min_value)\n",
    "    return num_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb1cc09-da1b-4293-9112-266bb3243cff",
   "metadata": {},
   "source": [
    "## Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b99bdd6-2f96-4dbf-b2df-64831314e5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2830743 entries, 0 to 2830742\n",
      "Data columns (total 97 columns):\n",
      " #   Column                       Dtype   \n",
      "---  ------                       -----   \n",
      " 0   destination_port             int64   \n",
      " 1   protocol                     int64   \n",
      " 2   flow_duration                int64   \n",
      " 3   total_fwd_packets            int64   \n",
      " 4   total_backward_packets       int64   \n",
      " 5   total_length_of_fwd_packets  float64 \n",
      " 6   total_length_of_bwd_packets  float64 \n",
      " 7   fwd_packet_length_max        float64 \n",
      " 8   fwd_packet_length_min        float64 \n",
      " 9   fwd_packet_length_mean       float64 \n",
      " 10  fwd_packet_length_std        float64 \n",
      " 11  bwd_packet_length_max        float64 \n",
      " 12  bwd_packet_length_min        float64 \n",
      " 13  bwd_packet_length_mean       float64 \n",
      " 14  bwd_packet_length_std        float64 \n",
      " 15  flow_bytes_s                 float64 \n",
      " 16  flow_packets_s               float64 \n",
      " 17  flow_iat_mean                float64 \n",
      " 18  flow_iat_std                 float64 \n",
      " 19  flow_iat_max                 float64 \n",
      " 20  flow_iat_min                 float64 \n",
      " 21  fwd_iat_total                float64 \n",
      " 22  fwd_iat_mean                 float64 \n",
      " 23  fwd_iat_std                  float64 \n",
      " 24  fwd_iat_max                  float64 \n",
      " 25  fwd_iat_min                  float64 \n",
      " 26  bwd_iat_total                float64 \n",
      " 27  bwd_iat_mean                 float64 \n",
      " 28  bwd_iat_std                  float64 \n",
      " 29  bwd_iat_max                  float64 \n",
      " 30  bwd_iat_min                  float64 \n",
      " 31  fwd_psh_flags                int64   \n",
      " 32  bwd_psh_flags                int64   \n",
      " 33  fwd_urg_flags                int64   \n",
      " 34  bwd_urg_flags                int64   \n",
      " 35  fwd_header_length            int64   \n",
      " 36  bwd_header_length            int64   \n",
      " 37  fwd_packets_s                float64 \n",
      " 38  bwd_packets_s                float64 \n",
      " 39  min_packet_length            float64 \n",
      " 40  max_packet_length            float64 \n",
      " 41  packet_length_mean           float64 \n",
      " 42  packet_length_std            float64 \n",
      " 43  packet_length_variance       float64 \n",
      " 44  fin_flag_count               int64   \n",
      " 45  syn_flag_count               int64   \n",
      " 46  rst_flag_count               int64   \n",
      " 47  psh_flag_count               int64   \n",
      " 48  ack_flag_count               int64   \n",
      " 49  urg_flag_count               int64   \n",
      " 50  cwe_flag_count               int64   \n",
      " 51  ece_flag_count               int64   \n",
      " 52  down_up_ratio                float64 \n",
      " 53  average_packet_size          float64 \n",
      " 54  avg_fwd_segment_size         float64 \n",
      " 55  avg_bwd_segment_size         float64 \n",
      " 56  fwd_header_length_1          int64   \n",
      " 57  fwd_avg_bytes_bulk           int64   \n",
      " 58  fwd_avg_packets_bulk         int64   \n",
      " 59  fwd_avg_bulk_rate            int64   \n",
      " 60  bwd_avg_bytes_bulk           int64   \n",
      " 61  bwd_avg_packets_bulk         int64   \n",
      " 62  bwd_avg_bulk_rate            int64   \n",
      " 63  subflow_fwd_packets          int64   \n",
      " 64  subflow_fwd_bytes            int64   \n",
      " 65  subflow_bwd_packets          int64   \n",
      " 66  subflow_bwd_bytes            int64   \n",
      " 67  init_win_bytes_forward       int64   \n",
      " 68  init_win_bytes_backward      int64   \n",
      " 69  act_data_pkt_fwd             int64   \n",
      " 70  min_seg_size_forward         int64   \n",
      " 71  active_mean                  float64 \n",
      " 72  active_std                   float64 \n",
      " 73  active_max                   float64 \n",
      " 74  active_min                   float64 \n",
      " 75  idle_mean                    float64 \n",
      " 76  idle_std                     float64 \n",
      " 77  idle_max                     float64 \n",
      " 78  idle_min                     float64 \n",
      " 79  label                        category\n",
      " 80  is_attack                    int64   \n",
      " 81  label_code                   int64   \n",
      " 82  is_dos_hulk                  int64   \n",
      " 83  is_portscan                  int64   \n",
      " 84  is_ddos                      int64   \n",
      " 85  is_dos_goldeneye             int64   \n",
      " 86  is_ftppatator                int64   \n",
      " 87  is_sshpatator                int64   \n",
      " 88  is_dos_slowloris             int64   \n",
      " 89  is_dos_slowhttptest          int64   \n",
      " 90  is_bot                       int64   \n",
      " 91  is_web_attack_brute_force    int64   \n",
      " 92  is_web_attack_xss            int64   \n",
      " 93  is_infiltration              int64   \n",
      " 94  is_web_attack_sql_injection  int64   \n",
      " 95  is_heartbleed                int64   \n",
      " 96  id                           int64   \n",
      "dtypes: category(1), float64(45), int64(51)\n",
      "memory usage: 2.0 GB\n"
     ]
    }
   ],
   "source": [
    "df = load_dataset(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2708b92-1dd6-4515-aa74-78ebcc79be2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_invalid(df):\n",
    "    # Select only numeric columns\n",
    "    numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    # Identify columns with NaN, infinite, or negative values\n",
    "    nan_columns = df[numeric_columns].columns[df[numeric_columns].isna().any()]\n",
    "    inf_columns = df[numeric_columns].columns[np.isinf(df[numeric_columns]).any()]\n",
    "\n",
    "    # Drop rows with NaN values (low percentage of NaN values)\n",
    "    df = df.dropna(subset=nan_columns)\n",
    "\n",
    "    # Drop rows with infinite values (assuming low percentage)\n",
    "    for col in inf_columns:\n",
    "        df = df[np.isfinite(df[col])]\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = replace_invalid(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "319ba2e8-e78d-45ac-8f38-2a9448150931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2827876 entries, 0 to 2830742\n",
      "Data columns (total 79 columns):\n",
      " #   Column                       Dtype  \n",
      "---  ------                       -----  \n",
      " 0   destination_port             int64  \n",
      " 1   protocol                     int64  \n",
      " 2   flow_duration                int64  \n",
      " 3   total_fwd_packets            int64  \n",
      " 4   total_backward_packets       int64  \n",
      " 5   total_length_of_fwd_packets  float64\n",
      " 6   total_length_of_bwd_packets  float64\n",
      " 7   fwd_packet_length_max        float64\n",
      " 8   fwd_packet_length_min        float64\n",
      " 9   fwd_packet_length_mean       float64\n",
      " 10  fwd_packet_length_std        float64\n",
      " 11  bwd_packet_length_max        float64\n",
      " 12  bwd_packet_length_min        float64\n",
      " 13  bwd_packet_length_mean       float64\n",
      " 14  bwd_packet_length_std        float64\n",
      " 15  flow_bytes_s                 float64\n",
      " 16  flow_packets_s               float64\n",
      " 17  flow_iat_mean                float64\n",
      " 18  flow_iat_std                 float64\n",
      " 19  flow_iat_max                 float64\n",
      " 20  flow_iat_min                 float64\n",
      " 21  fwd_iat_total                float64\n",
      " 22  fwd_iat_mean                 float64\n",
      " 23  fwd_iat_std                  float64\n",
      " 24  fwd_iat_max                  float64\n",
      " 25  fwd_iat_min                  float64\n",
      " 26  bwd_iat_total                float64\n",
      " 27  bwd_iat_mean                 float64\n",
      " 28  bwd_iat_std                  float64\n",
      " 29  bwd_iat_max                  float64\n",
      " 30  bwd_iat_min                  float64\n",
      " 31  fwd_psh_flags                int64  \n",
      " 32  bwd_psh_flags                int64  \n",
      " 33  fwd_urg_flags                int64  \n",
      " 34  bwd_urg_flags                int64  \n",
      " 35  fwd_header_length            int64  \n",
      " 36  bwd_header_length            int64  \n",
      " 37  fwd_packets_s                float64\n",
      " 38  bwd_packets_s                float64\n",
      " 39  min_packet_length            float64\n",
      " 40  max_packet_length            float64\n",
      " 41  packet_length_mean           float64\n",
      " 42  packet_length_std            float64\n",
      " 43  packet_length_variance       float64\n",
      " 44  fin_flag_count               int64  \n",
      " 45  syn_flag_count               int64  \n",
      " 46  rst_flag_count               int64  \n",
      " 47  psh_flag_count               int64  \n",
      " 48  ack_flag_count               int64  \n",
      " 49  urg_flag_count               int64  \n",
      " 50  cwe_flag_count               int64  \n",
      " 51  ece_flag_count               int64  \n",
      " 52  down_up_ratio                float64\n",
      " 53  average_packet_size          float64\n",
      " 54  avg_fwd_segment_size         float64\n",
      " 55  avg_bwd_segment_size         float64\n",
      " 56  fwd_header_length_1          int64  \n",
      " 57  fwd_avg_bytes_bulk           int64  \n",
      " 58  fwd_avg_packets_bulk         int64  \n",
      " 59  fwd_avg_bulk_rate            int64  \n",
      " 60  bwd_avg_bytes_bulk           int64  \n",
      " 61  bwd_avg_packets_bulk         int64  \n",
      " 62  bwd_avg_bulk_rate            int64  \n",
      " 63  subflow_fwd_packets          int64  \n",
      " 64  subflow_fwd_bytes            int64  \n",
      " 65  subflow_bwd_packets          int64  \n",
      " 66  subflow_bwd_bytes            int64  \n",
      " 67  init_win_bytes_forward       int64  \n",
      " 68  init_win_bytes_backward      int64  \n",
      " 69  act_data_pkt_fwd             int64  \n",
      " 70  min_seg_size_forward         int64  \n",
      " 71  active_mean                  float64\n",
      " 72  active_std                   float64\n",
      " 73  active_max                   float64\n",
      " 74  active_min                   float64\n",
      " 75  idle_mean                    float64\n",
      " 76  idle_std                     float64\n",
      " 77  idle_max                     float64\n",
      " 78  idle_min                     float64\n",
      "dtypes: float64(45), int64(34)\n",
      "memory usage: 1.7 GB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2827876 entries, 0 to 2830742\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Dtype   \n",
      "---  ------      -----   \n",
      " 0   label       category\n",
      " 1   label_code  int64   \n",
      " 2   is_attack   int64   \n",
      "dtypes: category(1), int64(2)\n",
      "memory usage: 67.4 MB\n",
      "label\n",
      "BENIGN                        2271320\n",
      "DoS Hulk                       230124\n",
      "PortScan                       158804\n",
      "DDoS                           128025\n",
      "DoS GoldenEye                   10293\n",
      "FTP-Patator                      7935\n",
      "SSH-Patator                      5897\n",
      "DoS slowloris                    5796\n",
      "DoS Slowhttptest                 5499\n",
      "Bot                              1956\n",
      "Web Attack - Brute Force         1507\n",
      "Web Attack - XSS                  652\n",
      "Infiltration                       36\n",
      "Web Attack - Sql Injection         21\n",
      "Heartbleed                         11\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:, 0:79]\n",
    "Y = df[['label', 'label_code', 'is_attack']]\n",
    "X.info()\n",
    "Y.info()\n",
    "print(Y.label.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d953d1f5-ef21-461e-b36e-1258e6f9debd",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ef9884-454d-4a3a-a09a-37e0f101f611",
   "metadata": {},
   "source": [
    "First, the columns with no variance are dropped as they have no impact on the target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4934212-189e-41d5-8be7-f47e147f88d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bwd_psh_flags', 'bwd_urg_flags', 'fwd_avg_bytes_bulk', 'fwd_avg_packets_bulk', 'fwd_avg_bulk_rate', 'bwd_avg_bytes_bulk', 'bwd_avg_packets_bulk', 'bwd_avg_bulk_rate']\n"
     ]
    }
   ],
   "source": [
    "stats = X.describe()\n",
    "std = stats.loc[\"std\"]\n",
    "features_no_var = std[std == 0.0].index\n",
    "# Exclude non-numeric columns (e.g., categorical columns) from the features with zero variance\n",
    "features_no_var_numeric = [col for col in features_no_var if col in X.select_dtypes(include=[np.number]).columns]\n",
    "print(features_no_var_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8622e582-cb4b-4ba6-b132-9dae905c013e",
   "metadata": {},
   "source": [
    "The destination port feature is dropped because it can act as a shortcut predictor and cause high overfitting for the training set as show in this [paper](https://link.springer.com/chapter/10.1007/978-3-031-09484-2_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e712c890-b08a-493b-84bf-f10c14fd6d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2827876 entries, 0 to 2830742\n",
      "Data columns (total 70 columns):\n",
      " #   Column                       Dtype  \n",
      "---  ------                       -----  \n",
      " 0   protocol                     int64  \n",
      " 1   flow_duration                int64  \n",
      " 2   total_fwd_packets            int64  \n",
      " 3   total_backward_packets       int64  \n",
      " 4   total_length_of_fwd_packets  float64\n",
      " 5   total_length_of_bwd_packets  float64\n",
      " 6   fwd_packet_length_max        float64\n",
      " 7   fwd_packet_length_min        float64\n",
      " 8   fwd_packet_length_mean       float64\n",
      " 9   fwd_packet_length_std        float64\n",
      " 10  bwd_packet_length_max        float64\n",
      " 11  bwd_packet_length_min        float64\n",
      " 12  bwd_packet_length_mean       float64\n",
      " 13  bwd_packet_length_std        float64\n",
      " 14  flow_bytes_s                 float64\n",
      " 15  flow_packets_s               float64\n",
      " 16  flow_iat_mean                float64\n",
      " 17  flow_iat_std                 float64\n",
      " 18  flow_iat_max                 float64\n",
      " 19  flow_iat_min                 float64\n",
      " 20  fwd_iat_total                float64\n",
      " 21  fwd_iat_mean                 float64\n",
      " 22  fwd_iat_std                  float64\n",
      " 23  fwd_iat_max                  float64\n",
      " 24  fwd_iat_min                  float64\n",
      " 25  bwd_iat_total                float64\n",
      " 26  bwd_iat_mean                 float64\n",
      " 27  bwd_iat_std                  float64\n",
      " 28  bwd_iat_max                  float64\n",
      " 29  bwd_iat_min                  float64\n",
      " 30  fwd_psh_flags                int64  \n",
      " 31  fwd_urg_flags                int64  \n",
      " 32  fwd_header_length            int64  \n",
      " 33  bwd_header_length            int64  \n",
      " 34  fwd_packets_s                float64\n",
      " 35  bwd_packets_s                float64\n",
      " 36  min_packet_length            float64\n",
      " 37  max_packet_length            float64\n",
      " 38  packet_length_mean           float64\n",
      " 39  packet_length_std            float64\n",
      " 40  packet_length_variance       float64\n",
      " 41  fin_flag_count               int64  \n",
      " 42  syn_flag_count               int64  \n",
      " 43  rst_flag_count               int64  \n",
      " 44  psh_flag_count               int64  \n",
      " 45  ack_flag_count               int64  \n",
      " 46  urg_flag_count               int64  \n",
      " 47  cwe_flag_count               int64  \n",
      " 48  ece_flag_count               int64  \n",
      " 49  down_up_ratio                float64\n",
      " 50  average_packet_size          float64\n",
      " 51  avg_fwd_segment_size         float64\n",
      " 52  avg_bwd_segment_size         float64\n",
      " 53  fwd_header_length_1          int64  \n",
      " 54  subflow_fwd_packets          int64  \n",
      " 55  subflow_fwd_bytes            int64  \n",
      " 56  subflow_bwd_packets          int64  \n",
      " 57  subflow_bwd_bytes            int64  \n",
      " 58  init_win_bytes_forward       int64  \n",
      " 59  init_win_bytes_backward      int64  \n",
      " 60  act_data_pkt_fwd             int64  \n",
      " 61  min_seg_size_forward         int64  \n",
      " 62  active_mean                  float64\n",
      " 63  active_std                   float64\n",
      " 64  active_max                   float64\n",
      " 65  active_min                   float64\n",
      " 66  idle_mean                    float64\n",
      " 67  idle_std                     float64\n",
      " 68  idle_max                     float64\n",
      " 69  idle_min                     float64\n",
      "dtypes: float64(45), int64(25)\n",
      "memory usage: 1.5 GB\n"
     ]
    }
   ],
   "source": [
    "X = X.drop(columns=features_no_var_numeric)\n",
    "X = X.drop(columns=['destination_port'])\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540f3994-4c2a-4c29-83f0-98b99faf6ba4",
   "metadata": {},
   "source": [
    "### Remove Collinear Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2dfab5e-ac09-48cd-ac69-e9bbe68f97fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2827876 entries, 0 to 2830742\n",
      "Data columns (total 39 columns):\n",
      " #   Column                       Dtype  \n",
      "---  ------                       -----  \n",
      " 0   protocol                     int64  \n",
      " 1   flow_duration                int64  \n",
      " 2   total_fwd_packets            int64  \n",
      " 3   total_length_of_fwd_packets  float64\n",
      " 4   fwd_packet_length_max        float64\n",
      " 5   fwd_packet_length_min        float64\n",
      " 6   fwd_packet_length_mean       float64\n",
      " 7   bwd_packet_length_max        float64\n",
      " 8   bwd_packet_length_min        float64\n",
      " 9   flow_bytes_s                 float64\n",
      " 10  flow_packets_s               float64\n",
      " 11  flow_iat_mean                float64\n",
      " 12  flow_iat_std                 float64\n",
      " 13  flow_iat_min                 float64\n",
      " 14  fwd_iat_min                  float64\n",
      " 15  bwd_iat_total                float64\n",
      " 16  bwd_iat_mean                 float64\n",
      " 17  bwd_iat_std                  float64\n",
      " 18  bwd_iat_max                  float64\n",
      " 19  fwd_psh_flags                int64  \n",
      " 20  fwd_urg_flags                int64  \n",
      " 21  fwd_header_length            int64  \n",
      " 22  bwd_header_length            int64  \n",
      " 23  bwd_packets_s                float64\n",
      " 24  min_packet_length            float64\n",
      " 25  fin_flag_count               int64  \n",
      " 26  rst_flag_count               int64  \n",
      " 27  psh_flag_count               int64  \n",
      " 28  ack_flag_count               int64  \n",
      " 29  urg_flag_count               int64  \n",
      " 30  down_up_ratio                float64\n",
      " 31  init_win_bytes_forward       int64  \n",
      " 32  init_win_bytes_backward      int64  \n",
      " 33  act_data_pkt_fwd             int64  \n",
      " 34  min_seg_size_forward         int64  \n",
      " 35  active_mean                  float64\n",
      " 36  active_std                   float64\n",
      " 37  active_max                   float64\n",
      " 38  idle_std                     float64\n",
      "dtypes: float64(23), int64(16)\n",
      "memory usage: 863.0 MB\n"
     ]
    }
   ],
   "source": [
    "def correlation_feature_selection(df, threshold=0.9):\n",
    "    corr_matrix = df.corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "    return df.drop(columns=to_drop)\n",
    "X = correlation_feature_selection(X)\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd84120b-0cb9-4107-bfd3-62a7096ad74c",
   "metadata": {},
   "source": [
    "### Information Gain Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8016bf7e-0f61-4687-9df5-c637a476d40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Feature  Information Gain\n",
      "1                 flow_duration          0.226366\n",
      "10               flow_packets_s          0.217815\n",
      "3   total_length_of_fwd_packets          0.213526\n",
      "11                flow_iat_mean          0.208003\n",
      "9                  flow_bytes_s          0.203715\n",
      "23                bwd_packets_s          0.199149\n",
      "31       init_win_bytes_forward          0.186198\n",
      "4         fwd_packet_length_max          0.185081\n",
      "6        fwd_packet_length_mean          0.182463\n",
      "12                 flow_iat_std          0.174562\n",
      "7         bwd_packet_length_max          0.165083\n",
      "32      init_win_bytes_backward          0.153307\n",
      "18                  bwd_iat_max          0.150998\n",
      "15                bwd_iat_total          0.146592\n",
      "16                 bwd_iat_mean          0.145545\n",
      "21            fwd_header_length          0.141878\n",
      "24            min_packet_length          0.112994\n",
      "5         fwd_packet_length_min          0.112187\n",
      "13                 flow_iat_min          0.106014\n",
      "2             total_fwd_packets          0.103694\n",
      "8         bwd_packet_length_min          0.099524\n",
      "0                      protocol          0.096396\n",
      "14                  fwd_iat_min          0.093734\n",
      "22            bwd_header_length          0.091322\n",
      "17                  bwd_iat_std          0.076317\n",
      "37                   active_max          0.059745\n",
      "35                  active_mean          0.059560\n",
      "33             act_data_pkt_fwd          0.053417\n",
      "27               psh_flag_count          0.039190\n",
      "34         min_seg_size_forward          0.037756\n",
      "38                     idle_std          0.032246\n",
      "36                   active_std          0.027820\n",
      "30                down_up_ratio          0.008744\n",
      "28               ack_flag_count          0.006740\n",
      "29               urg_flag_count          0.004985\n",
      "20                fwd_urg_flags          0.000722\n",
      "19                fwd_psh_flags          0.000211\n",
      "26               rst_flag_count          0.000000\n",
      "25               fin_flag_count          0.000000\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2827876 entries, 0 to 2830742\n",
      "Data columns (total 20 columns):\n",
      " #   Column                       Dtype  \n",
      "---  ------                       -----  \n",
      " 0   flow_duration                int64  \n",
      " 1   flow_packets_s               float64\n",
      " 2   total_length_of_fwd_packets  float64\n",
      " 3   flow_iat_mean                float64\n",
      " 4   flow_bytes_s                 float64\n",
      " 5   bwd_packets_s                float64\n",
      " 6   init_win_bytes_forward       int64  \n",
      " 7   fwd_packet_length_max        float64\n",
      " 8   fwd_packet_length_mean       float64\n",
      " 9   flow_iat_std                 float64\n",
      " 10  bwd_packet_length_max        float64\n",
      " 11  init_win_bytes_backward      int64  \n",
      " 12  bwd_iat_max                  float64\n",
      " 13  bwd_iat_total                float64\n",
      " 14  bwd_iat_mean                 float64\n",
      " 15  fwd_header_length            int64  \n",
      " 16  min_packet_length            float64\n",
      " 17  fwd_packet_length_min        float64\n",
      " 18  flow_iat_min                 float64\n",
      " 19  total_fwd_packets            int64  \n",
      "dtypes: float64(15), int64(5)\n",
      "memory usage: 453.1 MB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import pandas as pd\n",
    "\n",
    "def oversample_minority_classes(X, Y, sample_size=1000):\n",
    "    y = Y[\"label_code\"]\n",
    "    # Create a subset of the oversampled data\n",
    "    X_sample, _, y_sample, _ = train_test_split(X, y, train_size=sample_size, stratify=y, random_state=42)\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_resampled, y_resampled = ros.fit_resample(X_sample, y_sample)\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "def information_gain_feature_selection(X, Y, sample_size=1000):\n",
    "    # Create an oversampled subset of the data\n",
    "    X_sample, y_sample = oversample_minority_classes(X, Y, sample_size)\n",
    "    # Create is_attack column based on label_code\n",
    "    y_sample = (y_sample != 0).astype(int)\n",
    "    # Perform feature selection on the oversampled subset\n",
    "    info_gain = mutual_info_classif(X_sample, y_sample)\n",
    "    info_gain_df = pd.DataFrame({'Feature': X.columns, 'Information Gain': info_gain})\n",
    "    info_gain_df = info_gain_df.sort_values(by='Information Gain', ascending=False)\n",
    "    print(info_gain_df)\n",
    "    selected_features = info_gain_df[info_gain_df['Information Gain'] > 0.1]['Feature'].tolist()\n",
    "    return selected_features\n",
    "\n",
    "# Determine the selected features using the oversampled subset\n",
    "selected_features = information_gain_feature_selection(X, Y)\n",
    "\n",
    "# Apply the selected features to the main dataset\n",
    "X = X[selected_features]\n",
    "\n",
    "# Display information about the selected features\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0901d306-61ae-4134-a8d2-ddf0c2f8c1e0",
   "metadata": {},
   "source": [
    "## Split Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a501f4-aec6-4e22-b2dc-61b77e61d989",
   "metadata": {},
   "source": [
    "The dataset is split into a labelled and non labelled dataset. We keep a fully labelled copy of the dataset as a human oracle. As the non-labelled rows already contain a label, this will act as a human oracle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b4975bb-cedb-4666-ae44-cde95478341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to the entire dataset before splitting\n",
    "X_resampled, Y_resampled = resample_dataset(X, Y, min_samples=100000, attack_labels=attack_labels)\n",
    "\n",
    "# Combine resampled X and Y\n",
    "df_resampled = pd.concat([X_resampled, Y_resampled], axis=1)\n",
    "df_resampled['id'] = range(len(df_resampled))  # Reassign IDs after resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afe2f27f-c054-479b-a377-1f24ffd38426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3110618 entries, 0 to 3110617\n",
      "Data columns (total 25 columns):\n",
      " #   Column                       Dtype   \n",
      "---  ------                       -----   \n",
      " 0   flow_duration                float64 \n",
      " 1   flow_packets_s               float64 \n",
      " 2   total_length_of_fwd_packets  float64 \n",
      " 3   flow_iat_mean                float64 \n",
      " 4   flow_bytes_s                 float64 \n",
      " 5   bwd_packets_s                float64 \n",
      " 6   init_win_bytes_forward       float64 \n",
      " 7   fwd_packet_length_max        float64 \n",
      " 8   fwd_packet_length_mean       float64 \n",
      " 9   flow_iat_std                 float64 \n",
      " 10  bwd_packet_length_max        float64 \n",
      " 11  init_win_bytes_backward      float64 \n",
      " 12  bwd_iat_max                  float64 \n",
      " 13  bwd_iat_total                float64 \n",
      " 14  bwd_iat_mean                 float64 \n",
      " 15  fwd_header_length            float64 \n",
      " 16  min_packet_length            float64 \n",
      " 17  fwd_packet_length_min        float64 \n",
      " 18  flow_iat_min                 float64 \n",
      " 19  total_fwd_packets            float64 \n",
      " 20  label_code                   float64 \n",
      " 21  is_attack                    float64 \n",
      " 22  label                        category\n",
      " 23  id                           int64   \n",
      " 24  Labeled                      int64   \n",
      "dtypes: category(1), float64(22), int64(2)\n",
      "memory usage: 572.5 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Labeled\n",
       "0    2955088\n",
       "1     155530\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into labeled, unlabeled, and test portions\n",
    "def split_dataset(df, initial_labeled_ratio=0.05, test_size=0.2):\n",
    "    # First split out the test data\n",
    "    train_val_df, test_df = train_test_split(df, test_size=test_size, stratify=df['label'], random_state=42)\n",
    "    train_val_df['Labeled'] = 0    # Initially, mark all as unlabeled\n",
    "    # Then split the remaining data into labeled and unlabeled sets\n",
    "    labeled_df, unlabeled_df = train_test_split(train_val_df, test_size=1-initial_labeled_ratio, stratify=train_val_df['label'], random_state=42)\n",
    "    labeled_df['Labeled'] = 1  # Mark initial small portion as labeled\n",
    "    combined_df = pd.concat([labeled_df, unlabeled_df]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    return combined_df, test_df\n",
    "\n",
    "combined_df, test_df = split_dataset(df_resampled)\n",
    "combined_df.info()\n",
    "combined_df.Labeled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c3b3a20-1d34-495c-a23f-e6a926cca33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize the data and return the scaler used\n",
    "def standardize_data(X_train, X_test=None):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    if X_test is not None:\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        return X_train_scaled, X_test_scaled, scaler\n",
    "    return X_train_scaled, scaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9694ff8d-5271-4391-b9b5-0790e30d005f",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8da7d9b4-9494-4c24-9df9-3808916d3364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten, LSTM, TimeDistributed, RepeatVector, Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "metrics = {}\n",
    "# Build a simple neural network model\n",
    "# Define DNN model\n",
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_shape,)))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf23ea95-f3dc-4618-b290-3c6a910645b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified training function with dynamic SMOTE resampling\n",
    "def train_model_with_smote(combined_df, attack_labels, base_ratio=0.1, min_value=1000):\n",
    "    labeled_data = combined_df[combined_df['Labeled'] == 1]\n",
    "    X_train = labeled_data.drop(columns=['label', 'Labeled', 'id', 'is_attack'])\n",
    "    Y_train = labeled_data[['label', 'is_attack', 'label_code']]\n",
    "    \n",
    "    # Calculate dynamic min_samples based on the size of the labeled data\n",
    "    min_samples = calculate_min_samples(labeled_data, base_ratio, min_value)\n",
    "    \n",
    "    # Apply SMOTE to the labeled data\n",
    "    X_resampled, Y_resampled = resample_dataset(X_train, Y_train, min_samples, attack_labels)\n",
    "    \n",
    "    # Standardize the resampled data\n",
    "    X_resampled_scaled, scaler = standardize_data(X_resampled)\n",
    "    \n",
    "    # Train the model\n",
    "    model = build_model(X_resampled_scaled.shape[1])\n",
    "    model.fit(X_resampled_scaled, Y_resampled['is_attack'], epochs=10, batch_size=32, verbose=2)\n",
    "    \n",
    "    return model, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84f2df55-a2de-4d20-95d8-c43a7d52bef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for uncertainty sampling\n",
    "def uncertainty_sampling(model, unlabeled_data, scaler):\n",
    "    X_unlabeled = unlabeled_data.drop(columns=['label', 'Labeled', 'id', 'is_attack'])\n",
    "    \n",
    "    # Standardize the unlabeled data using the same scaler\n",
    "    X_unlabeled_scaled = scaler.transform(X_unlabeled)\n",
    "    \n",
    "    preds = model.predict(X_unlabeled_scaled)\n",
    "    uncertainty = np.abs(preds - 0.5).reshape(-1)\n",
    "    uncertain_indices = np.argsort(uncertainty)[:1000]  # Select 10 most uncertain samples\n",
    "    actual_indices = unlabeled_data.iloc[uncertain_indices].index.tolist()\n",
    "    return actual_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0962f616-700d-4712-a9d5-77df4794189a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "# Active learning loop with dynamic SMOTE resampling\n",
    "def active_learning_with_dynamic_smote(combined_df, test_df, n_rounds=5, attack_labels=None, base_ratio=0.1, min_value=1000):\n",
    "    round_acc = {}\n",
    "    \n",
    "    # Initial training of the model before entering the loop\n",
    "    model, scaler = train_model_with_smote(combined_df, attack_labels, base_ratio, min_value)\n",
    "    \n",
    "    for round_num in range(n_rounds):\n",
    "        print(f\"Round {round_num + 1} of Active Learning\")\n",
    "        \n",
    "        # Unlabeled data\n",
    "        unlabeled_data = combined_df[combined_df['Labeled'] == 0]\n",
    "        uncertain_indices = uncertainty_sampling(model, unlabeled_data, scaler)\n",
    "        \n",
    "        # \"Label\" the selected samples by setting 'Labeled' to 1\n",
    "        combined_df.loc[uncertain_indices, 'Labeled'] = 1\n",
    "        \n",
    "        # Retrain the model with dynamic SMOTE resampling\n",
    "        model, scaler = train_model_with_smote(combined_df, attack_labels, base_ratio, min_value)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        X_test = test_df.drop(columns=['label', 'Labeled', 'id', 'is_attack'])\n",
    "        y_test = test_df['is_attack']\n",
    "        \n",
    "        # Standardize the test data using the same scaler\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        # Evaluate model performance\n",
    "        loss, accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "        print(f\"Test Accuracy after Round {round_num + 1}: {accuracy}\\n\")\n",
    "        \n",
    "        # Store accuracy for this round\n",
    "        round_acc[round_num + 1] = accuracy\n",
    "    \n",
    "    return round_acc\n",
    "\n",
    "# Example usage\n",
    "round_acc = active_learning_with_dynamic_smote(combined_df, test_df, n_rounds=10, attack_labels=attack_labels, base_ratio=0.1, min_value=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0eb671-99a3-4c15-8875-6aab64a742e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to plot accuracy over rounds\n",
    "def plot_accuracies(round_acc_dict):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(list(round_acc_dict.keys()), list(round_acc_dict.values()), marker='.', label='Active Learning Accuracy')\n",
    "    \n",
    "    # Add horizontal line for a desired accuracy threshold (optional)\n",
    "    plt.axhline(y=0.97, color='r', linestyle='--', label='Desired Accuracy = 0.97')\n",
    "    \n",
    "    # Formatting\n",
    "    plt.title('Model Accuracy by Active Learning Round')\n",
    "    plt.xlabel('Round')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Plotting the results\n",
    "plot_accuracies(round_acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
